
import argparse
import json
from bert_attention.core.model import BERTModel
from bert_attention.core import extractor, information_flow

def cmd_attention(args):
    model = BERTModel(args.model, args.device)
    output = model.forward(args.text)

    if args.all_layers and args.all_heads:
        df = extractor.attention_to_dataframe(output)
    elif args.all_layers:
        df = extractor.attention_to_dataframe(output, head=args.head)
    elif args.all_heads:
        df = extractor.attention_to_dataframe(output, layer=args.layer)
    else:
        df = extractor.attention_to_dataframe(output, layer=args.layer, head=args.head)

    if args.format == 'csv':
        df.to_csv(args.output, index=False)
        print(f"Exported {len(df)} attention weights to {args.output}")
    elif args.format == 'json':
        df.to_json(args.output, orient='records', indent=2)
        print(f"Exported {len(df)} attention weights to {args.output}")
    elif args.format == 'parquet':
        df.to_parquet(args.output, index=False)
        print(f"Exported {len(df)} attention weights to {args.output}")
    else:
        raise ValueError(f"Unsupported format: {args.format}")

def cmd_tokens(args):
    model = BERTModel(args.model, args.device)
    output = model.forward(args.text)

    tokens_data = {
        'text': args.text,
        'tokens': output['tokens'],
        'num_tokens': len(output['tokens'])
    }

    if args.format == 'json':
        with open(args.output, 'w') as f:
            json.dump(tokens_data, f, indent=2)
        print(f"Exported {len(output['tokens'])} tokens to {args.output}")
    elif args.format == 'txt':
        with open(args.output, 'w') as f:
            for i, token in enumerate(output['tokens']):
                f.write(f"{i}\t{token}\n")
        print(f"Exported {len(output['tokens'])} tokens to {args.output}")
    else:
        raise ValueError(f"Unsupported format for tokens: {args.format}")

def cmd_qkv(args):
    model = BERTModel(args.model, args.device)
    output = model.forward(args.text)

    qkv_data = extractor.extract_qkv_matrices(output, model, args.layer, args.head)

    if args.format == 'npz':
        extractor.export_qkv_to_npz(qkv_data, args.output)
        print(f"Exported Q/K/V matrices for layer {args.layer}, head {args.head} to {args.output}")
    else:
        raise ValueError(f"Unsupported format for QKV: {args.format} (use 'npz')")

def cmd_rollout(args):
    model = BERTModel(args.model, args.device)
    output = model.forward(args.text)

    rollout_data = information_flow.compute_attention_rollout(
        output,
        exclude_special=not args.include_special,
        add_residual=args.add_residual
    )

    tokens = rollout_data['tokens']

    if args.format == 'csv':
        records = []
        for layer_idx, rollout_matrix in enumerate(rollout_data['per_layer']):
            for i, from_token in enumerate(tokens):
                for j, to_token in enumerate(tokens):
                    records.append({
                        'layer': layer_idx,
                        'from_token_idx': i,
                        'to_token_idx': j,
                        'from_token': from_token,
                        'to_token': to_token,
                        'rollout_weight': float(rollout_matrix[i, j])
                    })

        import pandas as pd
        df = pd.DataFrame(records)
        df.to_csv(args.output, index=False)
        print(f"Exported {len(records)} rollout weights to {args.output}")

    elif args.format == 'json':
        export_data = {
            'text': output['text'],
            'tokens': tokens,
            'num_layers': rollout_data['num_layers'],
            'rollout_per_layer': [r.tolist() for r in rollout_data['per_layer']],
            'final_rollout': rollout_data['final_rollout'].tolist()
        }
        with open(args.output, 'w') as f:
            json.dump(export_data, f, indent=2)
        print(f"Exported rollout data to {args.output}")

    elif args.format == 'npz':
        import numpy as np
        np.savez(
            args.output,
            rollout=rollout_data['rollout'],
            final_rollout=rollout_data['final_rollout'],
            tokens=np.array(tokens)
        )
        print(f"Exported rollout data to {args.output}")

def cmd_all(args):
    model = BERTModel(args.model, args.device)
    output = model.forward(args.text)

    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    attention_file = output_dir / 'attention.csv'
    df = extractor.attention_to_dataframe(output)
    df.to_csv(attention_file, index=False)
    print(f"Exported attention weights to {attention_file}")

    tokens_file = output_dir / 'tokens.json'
    tokens_data = {
        'text': args.text,
        'tokens': output['tokens'],
        'num_tokens': len(output['tokens'])
    }
    with open(tokens_file, 'w') as f:
        json.dump(tokens_data, f, indent=2)
    print(f"Exported tokens to {tokens_file}")

    metadata_file = output_dir / 'metadata.json'
    config = model.get_config()
    config['text'] = args.text
    config['num_tokens'] = len(output['tokens'])
    with open(metadata_file, 'w') as f:
        json.dump(config, f, indent=2)
    print(f"Exported metadata to {metadata_file}")

    print(f"\nAll data exported to {output_dir}")

def main():
    parser = argparse.ArgumentParser(
        description="Extract BERT attention data",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  bert-extract attention "The cat sat" --layer 0 --head 0 --output attn.csv

  bert-extract attention "Text" --all-layers --all-heads --output all_attn.csv

  bert-extract qkv "Text" --layer 0 --head 0 --output qkv.npz

  bert-extract tokens "Text" --output tokens.json

  bert-extract rollout "Text" --output rollout.csv

  bert-extract all "Text" --output-dir ./data/
        """
    )

    parser.add_argument('--model', default='bert-base-uncased',
                       help='BERT model name (default: bert-base-uncased)')
    parser.add_argument('--device', default='auto', choices=['auto', 'cpu', 'cuda'],
                       help='Compute device (default: auto)')

    subparsers = parser.add_subparsers(dest='command', required=True)

    attention_parser = subparsers.add_parser('attention', help='Extract attention matrices')
    attention_parser.add_argument('text', help='Input text')
    attention_parser.add_argument('--layer', type=int, default=0, help='Layer index (0-based)')
    attention_parser.add_argument('--head', type=int, default=0, help='Head index (0-based)')
    attention_parser.add_argument('--all-layers', action='store_true', help='Extract all layers')
    attention_parser.add_argument('--all-heads', action='store_true', help='Extract all heads')
    attention_parser.add_argument('--format', default='csv', choices=['csv', 'json', 'parquet'],
                                  help='Output format (default: csv)')
    attention_parser.add_argument('--output', '-o', required=True, help='Output file path')

    tokens_parser = subparsers.add_parser('tokens', help='Extract tokens')
    tokens_parser.add_argument('text', help='Input text')
    tokens_parser.add_argument('--format', default='json', choices=['json', 'txt'],
                              help='Output format (default: json)')
    tokens_parser.add_argument('--output', '-o', required=True, help='Output file path')

    qkv_parser = subparsers.add_parser('qkv', help='Extract Q/K/V matrices')
    qkv_parser.add_argument('text', help='Input text')
    qkv_parser.add_argument('--layer', type=int, required=True, help='Layer index (0-based)')
    qkv_parser.add_argument('--head', type=int, required=True, help='Head index (0-based)')
    qkv_parser.add_argument('--format', default='npz', choices=['npz'],
                           help='Output format (default: npz)')
    qkv_parser.add_argument('--output', '-o', required=True, help='Output file path')

    rollout_parser = subparsers.add_parser('rollout', help='Extract attention rollout')
    rollout_parser.add_argument('text', help='Input text')
    rollout_parser.add_argument('--include-special', action='store_true',
                               help='Include special tokens ([CLS], [SEP])')
    rollout_parser.add_argument('--add-residual', action='store_true', default=True,
                               help='Add residual connections (default: True)')
    rollout_parser.add_argument('--format', default='csv', choices=['csv', 'json', 'npz'],
                               help='Output format (default: csv)')
    rollout_parser.add_argument('--output', '-o', required=True, help='Output file path')

    all_parser = subparsers.add_parser('all', help='Extract all data')
    all_parser.add_argument('text', help='Input text')
    all_parser.add_argument('--output-dir', required=True, help='Output directory')

    args = parser.parse_args()

    if args.command == 'attention':
        cmd_attention(args)
    elif args.command == 'tokens':
        cmd_tokens(args)
    elif args.command == 'qkv':
        cmd_qkv(args)
    elif args.command == 'rollout':
        cmd_rollout(args)
    elif args.command == 'all':
        cmd_all(args)

if __name__ == '__main__':
    main()
